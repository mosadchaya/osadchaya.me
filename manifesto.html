<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Manifesto — Mariya Osadchaya</title>
  <meta name="description" content="Epistemological commitments — Mariya Osadchaya">
  <meta property="og:title" content="Manifesto — Mariya Osadchaya">
  <meta property="og:description" content="Anti-foundationalism, heuristics, continuous safety">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://osadchaya.me/manifesto.html">
  <meta property="og:image" content="https://osadchaya.me/assets/portrait.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <link rel="icon" type="image/svg+xml" href="assets/favicon.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="assets/favicon-32.png">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Goudy+Bookletter+1911&family=IBM+Plex+Mono:ital,wght@0,400;0,500;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="css/style.css">
</head>
<body data-page="4" data-active="manifesto.html" data-next="reading.html">

  <main class="page">
    <h1>Manifesto</h1>

    <blockquote>
      <p>Curiosity is my epistemological practice.</p>
    </blockquote>

    <p>I read in pairings—Houellebecq against Schopenhauer, Milton against Augustine—because single texts lie to you about how stable their claims are. Constitutional structures interest me for related but not identical reasons; they're frameworks that exist in permanent friction with what they govern. I studied law. I trained in pure mathematics. These feel like the same impulse to me.</p>

    <hr>

    <blockquote>
      <p>Heuristics over foundations.</p>
    </blockquote>

    <p>I'm anti-foundationalist about epistemology. Formulations like "emergence is where the danger lives" are heuristics to try on, not truth claims. We build increasingly complex world models—of markets, of language, of risk—without mistaking them for epistemic truth. The search for the right space is itself interminable, but productive. In mathematics, a function that seems multivalued becomes single-valued when you recognize the space it actually lives on. But the "right space" is never fully available, only approachable through traces.</p>

    <p>This is a different claim than "find the right framework and the confusion resolves." It's closer to: the approximation is always incomplete, and the incompleteness is where the work lives.</p>

    <hr>

    <blockquote>
      <p>Safety is continuous, not eschatological.</p>
    </blockquote>

    <p>Much of the generalist AI safety literature echoes an eschatological structure—a rapture point after which additional work becomes moot. I am not saying to never think about existential risk; that would be ridiculous. But the binary framing (pre-AGI/post-AGI, conscious/not-conscious) prevents useful heuristic development for the problems we have now.</p>

    <p>The interesting work is in the full spectrum: short-term operational risk (state actors, model manipulation, adversarial attack surfaces), medium-term systemic risk (what does it mean for society to adopt LLM use en masse?), and the consciousness constraints that arise from lack of being-in-world. Build detection mechanisms for ongoing deployment. Don't wait for the singular catastrophe.</p>
  </main>

  <script src="js/site.js"></script>
</body>
</html>
